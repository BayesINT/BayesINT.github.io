% For now put all the themes in one file, but split out later as more convenient.
\section{Themes}  \label{sec:themes}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\subsection{Implication of Bayesian philosophy/practices/concepts}  \label{subsec:implications}
%
%[\emph{This may go in section~\ref{subsec:conceptual_issues} instead.}]
%
%\bi
%  \I emphasis of posterior vs.\ minimizing of $\chi^2$
%  \I sampling vs.\ optimization  
%\ei
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Likelihood function and Bayes theorem}  \label{subsec:L}

\bi
  \I Recall Bayes theorem introduced (probably) in sec. \ref{subsec:basic_Bayes}
  \I Define the likelihood function in both simple (1D) and advanced (ND) case
  \I Posing the problem (and the notations): data = model + random error
  $$ y(x) = \eta(x) + \epsilon  $$
  \I Everything else follows: GP + MCMC to actually determine $x$, variations on 
     the same theme for model defects ($\epsilon \rightarrow \epsilon + \delta(x)$ 
     and augmented $\chi^2$, choice of prior for $x$, etc.
\ei

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Gaussian Process (GP) as a tool}  \label{subsec:GP_tool}

\bi
  \I GP simulates correlations between parameters
  \I emulators
  \I discrepant functions / random effects 
  \I linear regression $\rightarrow$ GP
  \I limitations: bad at emulating waveforms (Lackey)
\ei

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Discrepant functions / random effects}  \label{subsec:discrepant}

\bi
  \I Model discrepancy: mock up what we know about the intrinsic limitations of 
     our model into the posterior
  \I data = model + truly random error + systematic bias
  $$ y(x) = \eta(x) + \epsilon + \delta(x) $$
  \I Example of nuclear masses: deviations near closed shells (particle-vibration 
     coupling, pairing phase transition), at $N=Z$ (Wigner energy), in transitional 
     nuclei (shape coexistence) are known but sometimes very hard (=computationally) 
     to model
  \I Using model discrepancies allow ``professional'' fitting of a model at some 
     approximation while resulting parametrization is valid at higher resolution/order.
     Ex.: fit at SR-EDF level, but parameters hopefully valid at MR-EDF
  \I Avoid overfitting
\ei

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{\texorpdfstring{$\chi^2$}{chi-squared} and dofs}  \label{subsec:}

   \bi 
       \I $\chi^2/$dof is not meaningful for Bayesian statistics
       \I dofs when there are priors
       \I how should one count dofs?
       \I augmented $\chi^2$: distance from the prior (Bartek's talk?)
       \I When does $\chi^2/$dof make sense?
       \I AWS: Bayes' factors and Occam's razor
   \ei    

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Pitfalls}  \label{subsec:pitfalls}

  \bi
    \I using same data to estimate priors and determine uncertainty
  \ei


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Model selection / comparison (or metrics)}  \label{subsec:model_comparison}

  \bi
    \I laundry list of approaches (see Vera's talk)
    \I new approach for nuclear physics: mixture models (supermodels)
  \ei


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Selection of priors}  \label{subsec:selecting_priors}

  \bi
    \I uniform vs. where it makes a difference
    \I knowledge of underlying model 
    \I running against the boundary
    \I AWS: Jeffrey's priors and invariance with respect to
    parameter transformations
  \ei


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Use of MCMC}  \label{subsec:using_mcmc}

Monte Carlo integration methods are based on the idea that, if one
has a way to generate a random deviate from a probability distribution
defined by the integrand, then one can replace the integral by a sum
(the same formalism applies trivially to multi-dimensional integrals)
\begin{equation}
  \int_a^{b} f(x) dx \approx \frac{\left( b-a\right)}{N} \sum_i p_i 
\end{equation}
where $p_i$ is a list of $N$ random numbers selected from the
probability distribution $f(x)$ with $x \in [a,b]$. Monte
Carlo is typically an efficient method of integration
over direct integration for
problems with large dimensionality. In some cases,
selecting a random deviate from $f(x)$ is not straightforward.
This problem can be handled by importance sampling: one decomposes
$f(x)=g(x)h(x)$ where $g(x)$ is slowly varying with $x$ and $h(x)$
is a function which one can more easily sample random deviates from.
An excellent review is in Sokal (1980) [insert ref. here].

Markov chain Monte Carlo is a type of
importance sampling where one generates random deviates from $h(x)$
by generating a ``Markov chain'', a set of numbers whose distribution
asymptotically approaches $h(x)$.

  \bi
    \I must be able to evaluate quickly enough
    \I fast model vs. good emulator vs. slow function (dictates what you do)
    \I burn-in as usual; is checking autocorrelation and skipping critical?
    \I nested sampling?
    \I AWS: MCMC pitfalls: Skipping points when the likelihood
    function is zero (bad idea)
  \ei


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Specific issues}  \label{subsec:issues}

  \bi
    \I Instabilities in parameter space
      \bi
        \I undefined $\chi^2$
        \I diagnostics (e.g., response function) 
        \I alternatives?
      \ei     
      \I Bayesian inference for functions rather than for parameters
      \I AWS: Normalization of conditional probabilities?
  \ei


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Understanding of model function}  \label{subsec:model_function}

  \bi
    \I ???
  \ei


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsection{}  \label{subsec:}
%   \bi
%     \I 
%   \ei

